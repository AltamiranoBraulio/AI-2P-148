import numpy as np
import random

# ConfiguraciÃ³n del mapa
island = [
    ['ğŸŒ', 'â“', 'ğŸ›–', 'â“', 'ğŸš'],
    ['â“', 'ğŸ•³ï¸', 'â“', 'ğŸ•³ï¸', 'â“'],
    ['â“', 'â“', 'ğŸŒ', 'â“', 'â“']
]

reward_map = {
    'â“': -0.04,
    'ğŸŒ': 1,
    'ğŸ›–': 2,
    'ğŸš': 10,
    'ğŸ•³ï¸': -10
}

rows, cols = len(island), len(island[0])
states = [(i, j) for i in range(rows) for j in range(cols) if island[i][j] != 'ğŸ•³ï¸']
actions = ['â†‘', 'â†“', 'â†', 'â†’']
gamma = 0.9
theta = 0.01

# Probabilidad de transiciÃ³n (80% directo, 10% a cada lado perpendicular)
transition_probs = {
    'â†‘': [('â†‘', 0.8), ('â†', 0.1), ('â†’', 0.1)],
    'â†“': [('â†“', 0.8), ('â†', 0.1), ('â†’', 0.1)],
    'â†': [('â†', 0.8), ('â†‘', 0.1), ('â†“', 0.1)],
    'â†’': [('â†’', 0.8), ('â†‘', 0.1), ('â†“', 0.1)]
}

move_delta = {
    'â†‘': (-1, 0),
    'â†“': (1, 0),
    'â†': (0, -1),
    'â†’': (0, 1)
}

V = np.zeros((rows, cols))

def is_valid(i, j):
    return 0 <= i < rows and 0 <= j < cols and island[i][j] != 'ğŸ•³ï¸'

def move(i, j, action):
    di, dj = move_delta[action]
    ni, nj = i + di, j + dj
    return (ni, nj) if is_valid(ni, nj) else (i, j)

def value_iteration():
    while True:
        delta = 0
        new_V = V.copy()
        for i, j in states:
            max_val = float('-inf')
            for a in actions:
                val = 0
                for dir, prob in transition_probs[a]:
                    ni, nj = move(i, j, dir)
                    reward = reward_map[island[ni][nj]]
                    val += prob * (reward + gamma * V[ni][nj])
                max_val = max(max_val, val)
            delta = max(delta, abs(max_val - V[i][j]))
            new_V[i][j] = max_val
        V[:, :] = new_V
        if delta < theta:
            break

def extract_policy():
    policy = [['â¬›' for _ in range(cols)] for _ in range(rows)]
    for i, j in states:
        best_action = None
        best_value = float('-inf')
        for a in actions:
            val = 0
            for dir, prob in transition_probs[a]:
                ni, nj = move(i, j, dir)
                reward = reward_map[island[ni][nj]]
                val += prob * (reward + gamma * V[ni][nj])
            if val > best_value:
                best_value = val
                best_action = a
        policy[i][j] = {'â†‘': 'ğŸ”¼', 'â†“': 'ğŸ”½', 'â†': 'â—€ï¸', 'â†’': 'â–¶ï¸'}[best_action]
    return policy

def print_policy(policy):
    print("\nğŸ§­ POLÃTICA Ã“PTIMA PARA SOBREVIVIR EN LA ISLA:")
    for i in range(rows):
        row = ''
        for j in range(cols):
            if island[i][j] == 'ğŸ•³ï¸':
                row += 'ğŸ•³ï¸ '
            elif island[i][j] == 'ğŸš':
                row += 'ğŸš '
            else:
                row += policy[i][j] + ' '
        print(row)

value_iteration()
final_policy = extract_policy()
print_policy(final_policy)
