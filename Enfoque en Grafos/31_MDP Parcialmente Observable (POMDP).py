import random

# --- Definici贸n del mundo ---
states = ['Bosque', 'Playa', 'Monta帽a', 'Cueva', 'Tesoro']
actions = ['Norte', 'Sur', 'Este', 'Oeste']
observations = ['Olor a sal', 'Ecos', 'Sombra', 'Aroma dulce', 'Silencio']

# Modelo de transici贸n simple: moverse aleatoriamente
def transition(state, action):
    probs = {
        'Bosque': {'Norte': 'Monta帽a', 'Sur': 'Playa', 'Este': 'Cueva', 'Oeste': 'Bosque'},
        'Playa': {'Norte': 'Bosque', 'Sur': 'Playa', 'Este': 'Playa', 'Oeste': 'Playa'},
        'Monta帽a': {'Norte': 'Monta帽a', 'Sur': 'Bosque', 'Este': 'Monta帽a', 'Oeste': 'Monta帽a'},
        'Cueva': {'Norte': 'Cueva', 'Sur': 'Tesoro', 'Este': 'Cueva', 'Oeste': 'Bosque'},
        'Tesoro': {'Norte': 'Tesoro', 'Sur': 'Tesoro', 'Este': 'Tesoro', 'Oeste': 'Tesoro'}
    }
    return probs[state].get(action, state)

# Modelo de observaci贸n: probabilidades de lo que se percibe en cada estado
observation_model = {
    'Bosque': ['Sombra', 'Silencio'],
    'Playa': ['Olor a sal', 'Silencio'],
    'Monta帽a': ['Ecos', 'Sombra'],
    'Cueva': ['Ecos', 'Aroma dulce'],
    'Tesoro': ['Aroma dulce', 'Silencio']
}

# Funci贸n de recompensa
def reward(state):
    if state == 'Tesoro':
        return 100
    else:
        return -1

# Inicializaci贸n: creencia uniforme
belief = {state: 1/len(states) for state in states}

# Funci贸n para actualizar la creencia basada en la observaci贸n
def update_belief(belief, observation):
    new_belief = {}
    for state in states:
        if observation in observation_model[state]:
            new_belief[state] = belief[state] * 0.9  # Alta probabilidad si la observaci贸n es t铆pica
        else:
            new_belief[state] = belief[state] * 0.1  # Baja probabilidad si no es t铆pica
    # Normalizar
    total = sum(new_belief.values())
    for state in new_belief:
        new_belief[state] /= total
    return new_belief

# Funci贸n para elegir la acci贸n basada en la creencia
def choose_action(belief):
    # Simplemente ir hacia el lugar que creemos m谩s probable que tenga el Tesoro
    best_state = max(belief, key=belief.get)
    if best_state == 'Cueva':
        return 'Sur'
    elif best_state == 'Bosque':
        return random.choice(['Este', 'Sur'])
    elif best_state == 'Monta帽a':
        return 'Sur'
    elif best_state == 'Playa':
        return 'Norte'
    else:
        return random.choice(actions)

# Simulaci贸n principal
current_state = random.choice(states)
print(f" Estado inicial oculto: {current_state}")

for step in range(10):
    obs = random.choice(observation_model[current_state])
    print(f"\n Observaci贸n recibida: {obs}")
    belief = update_belief(belief, obs)
    print(f" Creencia actualizada: {belief}")
    action = choose_action(belief)
    print(f"★ Acci贸n elegida: {action}")
    current_state = transition(current_state, action)
    print(f" Nuevo estado oculto: {current_state}")
    if current_state == 'Tesoro':
        print(" 隆Tesoro encontrado!")
        break
