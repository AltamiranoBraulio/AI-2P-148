import random  # Importamos random, aunque en este c√≥digo no se usa (pero podr√≠as usarlo para generar observaciones aleatorias)

# ---------------------------------------------
# üîí Estados ocultos (Lo que no podemos ver directamente)
# Ejemplo: qu√© est√° haciendo la persona realmente.
# ---------------------------------------------
estados = ['Trabajando', 'De vacaciones', 'Enfermo']

# ---------------------------------------------
# üëÄ Observaciones posibles (Lo que s√≠ vemos)
# Ejemplo: c√≥mo se comporta externamente (llamadas, correos, silencio).
# ---------------------------------------------
observaciones_posibles = ['Llamadas', 'Correo', 'Silencio']

# ---------------------------------------------
# üîÑ Matriz de transici√≥n entre estados ocultos
# Dice la probabilidad de pasar de un estado oculto a otro.
# Por ejemplo: si est√° "Trabajando" hoy, ¬øqu√© probabilidad hay de que ma√±ana est√© "De vacaciones"?
# Cada fila suma aproximadamente 1 (porque cubre todas las opciones posibles desde un estado).
# ---------------------------------------------
transiciones = {
    'Trabajando': {'Trabajando': 0.6, 'De vacaciones': 0.3, 'Enfermo': 0.1},
    'De vacaciones': {'Trabajando': 0.2, 'De vacaciones': 0.7, 'Enfermo': 0.1},
    'Enfermo': {'Trabajando': 0.3, 'De vacaciones': 0.2, 'Enfermo': 0.5},
}

# ---------------------------------------------
# üì° Matriz de emisi√≥n (tambi√©n llamada sensor model)
# Relaciona cada estado oculto con las probabilidades de cada observaci√≥n visible.
# Ejemplo: Si est√° "Enfermo", probablemente haya "Silencio" (80%)
# ---------------------------------------------
emisiones = {
    'Trabajando': {'Llamadas': 0.7, 'Correo': 0.2, 'Silencio': 0.1},
    'De vacaciones': {'Llamadas': 0.3, 'Correo': 0.1, 'Silencio': 0.6},
    'Enfermo': {'Llamadas': 0.1, 'Correo': 0.1, 'Silencio': 0.8},
}

# ---------------------------------------------
# üé≤ Distribuci√≥n inicial (creencia inicial)
# Nos dice en qu√© estado creemos que est√° la persona al principio.
# Ejemplo: 50% de probabilidad de que est√© "Trabajando" al inicio.
# ---------------------------------------------
inicial = {'Trabajando': 0.5, 'De vacaciones': 0.3, 'Enfermo': 0.2}

# ---------------------------------------------
# üîÑ Funci√≥n para normalizar cualquier distribuci√≥n
# Se asegura de que los valores sumen 1 (probabilidades v√°lidas).
# No es usada en Viterbi, pero es √∫til en otros algoritmos.
# ---------------------------------------------
def normalizar(distribucion):
    total = sum(distribucion.values())
    return {k: v / total for k, v in distribucion.items()}

# ---------------------------------------------
# üöÄ Algoritmo Viterbi para decodificaci√≥n
# Dado una secuencia de observaciones, encuentra la secuencia m√°s probable de estados ocultos.
# Esto es como que un detective trate de adivinar qu√© pas√≥ en realidad bas√°ndose en pistas.
# ---------------------------------------------
def viterbi(observaciones):
    V = [{}]  # Aqu√≠ guardamos la probabilidad m√°xima de cada estado en cada tiempo.
    path = {}  # Aqu√≠ guardamos el camino (la secuencia de estados) m√°s probable.

    # ‚è∞ Paso de inicializaci√≥n con la primera observaci√≥n
    for estado in estados:
        # La probabilidad inicial es: probabilidad de estar en ese estado al inicio √ó probabilidad de emitir la observaci√≥n
        V[0][estado] = inicial[estado] * emisiones[estado][observaciones[0]]
        # Guardamos que al inicio, el camino es solo este estado
        path[estado] = [estado]

    # üîÑ Ahora recorremos el resto de observaciones (t = 1 hasta el final)
    for t in range(1, len(observaciones)):
        V.append({})  # Agregamos un nuevo paso de tiempo
        nuevo_path = {}  # Para guardar los caminos actualizados

        for estado_actual in estados:
            # Para cada estado actual, buscamos el estado anterior que maximiza la probabilidad
            (prob_max, estado_previo) = max(
                # Multiplicamos:
                # 1) la mejor probabilidad hasta el estado anterior
                # 2) la probabilidad de transici√≥n al estado actual
                # 3) la probabilidad de emitir la observaci√≥n actual desde este estado
                (V[t-1][estado_anterior] * transiciones[estado_anterior][estado_actual] * emisiones[estado_actual][observaciones[t]], estado_anterior)
                for estado_anterior in estados
            )
            # Guardamos la mejor probabilidad para este estado en tiempo t
            V[t][estado_actual] = prob_max
            # Guardamos el mejor camino que llega aqu√≠
            nuevo_path[estado_actual] = path[estado_previo] + [estado_actual]

        # Actualizamos todos los caminos
        path = nuevo_path

    # ‚úÖ Al final, seleccionamos el estado final que tenga la probabilidad m√°s alta
    (prob_final, estado_final) = max((V[-1][estado], estado) for estado in estados)
    # Devolvemos el camino (secuencia de estados) y su probabilidad
    return path[estado_final], prob_final

# ---------------------------------------------
# üé≤ Secuencia de observaciones (simuladas)
# Lo que el detective recibe como pistas externas
# ---------------------------------------------
observaciones = ['Llamadas', 'Silencio', 'Silencio', 'Correo', 'Llamadas', 'Silencio']

# ---------------------------------------------
# üöÄ Ejecutamos el algoritmo Viterbi con nuestras observaciones
# ---------------------------------------------
print("üîé Observaciones del detective:")
print(observaciones)  # Mostramos lo que recibimos como pistas

# Corremos Viterbi para encontrar la secuencia oculta m√°s probable
camino_mas_probable, probabilidad = viterbi(observaciones)

# Mostramos la secuencia de estados ocultos (la explicaci√≥n interna m√°s probable)
print("\nüïµÔ∏è‚Äç‚ôÇÔ∏è Secuencia m√°s probable de actividades ocultas:")
print(camino_mas_probable)

# Mostramos la probabilidad total de este camino (qu√© tan seguro est√° el algoritmo)
print(f"\nüéØ Probabilidad total del camino: {probabilidad:.5f}")
