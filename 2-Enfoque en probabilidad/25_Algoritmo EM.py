# ---------------------------------------------
# üå∏ Clustering de flores usando Algoritmo EM (Gaussian Mixture)
# ---------------------------------------------

# Importamos numpy para manejar arreglos num√©ricos
import numpy as np
# Importamos matplotlib para crear gr√°ficos
import matplotlib.pyplot as plt
# Importamos datasets reales de sklearn (como Iris)
from sklearn import datasets
# Importamos el modelo GaussianMixture que usa el algoritmo EM
from sklearn.mixture import GaussianMixture

# ---------------------------------------------
# 1. üìö Cargar datos reales (dataset Iris)

# Cargamos el famoso dataset Iris que tiene datos de flores
iris = datasets.load_iris()

# Seleccionamos solo las primeras 2 caracter√≠sticas:
# (columna 0: largo del s√©palo, columna 1: ancho del s√©palo)
# Esto lo hacemos para poder graficar en 2D.
X = iris.data[:, :2]

# Guardamos las etiquetas reales (0 = Setosa, 1 = Versicolor, 2 = Virginica)
y_real = iris.target

# ---------------------------------------------
# 2. üîÑ Crear modelo EM con 3 componentes (porque hay 3 tipos de flores)

# Creamos un modelo GaussianMixture:
# - n_components=3 porque sabemos que hay 3 tipos de flores.
# - covariance_type='full' permite que cada componente tenga su propia forma el√≠ptica.
# - random_state=0 asegura que los resultados sean siempre los mismos si volvemos a ejecutar.
modelo_em = GaussianMixture(n_components=3, covariance_type='full', random_state=0)

# Ajustamos el modelo a nuestros datos X:
# El algoritmo EM comienza a estimar las "mezclas gaussianas" que mejor explican los datos.
modelo_em.fit(X)

# Ahora usamos el modelo entrenado para predecir a qu√© grupo (cluster) pertenece cada flor.
# Esto devuelve un array con valores 0, 1 o 2 indicando el grupo asignado.
predicciones = modelo_em.predict(X)

# ---------------------------------------------
# 3. üé® Visualizar los resultados

# Creamos una nueva figura de tama√±o 8x4 pulgadas
plt.figure(figsize=(8, 4))

# -----------------
# Subplot 1: Clusters hallados por EM
# -----------------

# Creamos el primer subplot (1 fila, 2 columnas, posici√≥n 1)
plt.subplot(1, 2, 1)

# Dibujamos un scatter plot (diagrama de puntos)
# - X[:, 0]: eje x (largo del s√©palo)
# - X[:, 1]: eje y (ancho del s√©palo)
# - c=predicciones: coloreamos los puntos seg√∫n el cluster que el modelo EM asign√≥
# - cmap='viridis': usamos una paleta de colores bonita
# - s=50: tama√±o de los puntos
plt.scatter(X[:, 0], X[:, 1], c=predicciones, cmap='viridis', s=50)

# T√≠tulo del gr√°fico
plt.title('üîÆ Clusters Encontrados (EM)')

# Etiqueta del eje x
plt.xlabel('Largo S√©palo (cm)')

# Etiqueta del eje y
plt.ylabel('Ancho S√©palo (cm)')

# -----------------
# Subplot 2: Etiquetas reales (por comparaci√≥n)
# -----------------

# Creamos el segundo subplot (1 fila, 2 columnas, posici√≥n 2)
plt.subplot(1, 2, 2)

# Dibujamos otro scatter plot
# - Esta vez coloreamos usando y_real, que son las etiquetas verdaderas del dataset.
plt.scatter(X[:, 0], X[:, 1], c=y_real, cmap='viridis', s=50)

# T√≠tulo del gr√°fico
plt.title('‚úÖ Clusters Reales (Iris)')

# Etiqueta del eje x
plt.xlabel('Largo S√©palo (cm)')

# Etiqueta del eje y
plt.ylabel('Ancho S√©palo (cm)')

# -----------------
# Ajustamos autom√°ticamente los espacios entre subplots para que no se encimen
plt.tight_layout()

# Mostramos la ventana con las 2 gr√°ficas
plt.show()
